{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b24aee",
   "metadata": {},
   "source": [
    "## 1.3 Matrices and Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca5381",
   "metadata": {},
   "source": [
    "용어 정리\n",
    "\n",
    "row vector(row matrix)\n",
    "column vector(column matrix)\n",
    "scalars\n",
    "\n",
    "squard matrix of order n\n",
    "main diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225bf842",
   "metadata": {},
   "source": [
    "### Matrix Multiplication by Columns and by Rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1279912c",
   "metadata": {},
   "source": [
    "Partitioned Matrix\n",
    "\n",
    "3가지 submatrices로 쪼갤 수 있음\n",
    "\n",
    "![submatrices](../assets/ch01_3_submatrices.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b57a05",
   "metadata": {},
   "source": [
    "Partitioning이라는 테크닉이 자주 쓰이는데 이걸 활용하면 전체를 구하지 않고 특정 열이나 행에 대해서만 구할 수 있음\n",
    "\n",
    "\"뒤ROW 앞COL\"\n",
    "\n",
    "1. entry method\n",
    "2. row method(뒤 Row 방식 -> 뒤에 column by column 으로 놓임)\n",
    "3. column method(앞 Col 방식 -> 앞에 row by row로 놓임)\n",
    "\n",
    "![partitioning](../assets/ch01_03.partitioning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef0fef",
   "metadata": {},
   "source": [
    "## Matrix Products as Linear Combinations  \n",
    "  : n x 1 짜리 column vector 하나가 오른쪽에 오는 경우  \n",
    "  : 이 경우가 방정식 푸는거랑 비슷한 꼴인데 이 꼴이 가지는 특징을 공부하면 방정식 푸는거에 향후 응용 가능!\n",
    "\n",
    "![linearCombination](../assets/ch01_03.linearCombination.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c82de61",
   "metadata": {},
   "source": [
    "### Column-Row Expansion\n",
    "\n",
    "A[x1 x2 x3 ...] = [Ax1 Ax2 Ax3 ...] 특징과, linear combination 특성을 이용하는 방법이 다음과 같이 있다. \n",
    "\n",
    "![example09](../assets/ch01_03.Example9.png)  \n",
    "\n",
    "  \n",
    "행렬곱 AB가 있을 떄, A의 열벡터와 B 행벡터 각각을  $c_1r_1 + c_2r_2 + c_3r_3 + c_4r_4 + ...$로도 나타낼 수 있는데 이를 Column-Row Expansion이라고 함.\n",
    "\n",
    "이게 여기에선 임팩트가 없어보이지만 사실 이 표현 방법이 공학적 응용에 있어서 매우매우 중요함!!  \n",
    "\n",
    "- 이유1 : 행렬곱을 rank가 1인 행렬들의 합으로 표현할 수 있음 -> **SVD(특이값 분해)**, **PCA**, **추천시스템(행렬 완성)** 에서 자주 활용\n",
    "\n",
    "- 이유2 : 직접 행렬곱을 계산하지 않고 시각적 / 개념적으로 접근할 때 사용 -> 행렬곱을 각 **열 X 행** 단위로 이해하면 구조적으로 **AB행렬의 방향성 / 패턴**을 분석 -> 공간해석, 변환해석(이미지 필터링)\n",
    "\n",
    "- 이유3 : Low-rank 근사나 필터링을 빠르게 계산할 때 사용 -> **이미지 처리나 신호처리** 등에서 **핵심 feature**를 갖는 부분만 골라서 곱할 수 있음\n",
    "\n",
    "- 이유4 : 뉴럴 네트워크에서 Linear Layer 구조 분석 -> Fully Connected Layer의 weight matrix를 column-row 형식으로 보면, 입력 벡터에 **어떤 filter가 곱해졌는지**를 선형 결합 구조로 분석 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2436a",
   "metadata": {},
   "source": [
    "## Transpose AND Trace\n",
    "\n",
    "Transpose는 행과 열을 뒤집는 거고, Trace는 Square Matrix의 경우에 대각선에 있는 값들을 모두 더한 것  \n",
    "\n",
    "단순한 정의는 이러하지만 다음과 같은 쓰임이 각각 있다.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 Transpose vs Trace\n",
    "\n",
    "### ✅ 1. Transpose (전치)\n",
    "\n",
    "> Aᵀ: 행(row)과 열(column)을 뒤집은 행렬\n",
    "\n",
    "---\n",
    "\n",
    "#### 💡 Transpose의 활용 예\n",
    "\n",
    "- **내적 (dot product)** 계산  \n",
    "  `xᵀy` 형태로 벡터 내적을 정의할 때 사용\n",
    "\n",
    "- **대칭행렬 확인**  \n",
    "  `A = Aᵀ`이면 대칭행렬 → 공분산 행렬 등에서 중요\n",
    "\n",
    "- **역전파 (Backpropagation)**  \n",
    "  신경망 학습 시, **다차원 파라미터의 미분 결과를 전파**할 때 transpose가 필수적으로 등장함.\n",
    "\n",
    "  예를 들어 다음과 같은 선형 변환이 있다고 가정하자: y = Wx\n",
    "\n",
    "  \n",
    "여기서:\n",
    "- `W`: weight matrix (`m × n`)\n",
    "- `x`: 입력 벡터 (`n × 1`)\n",
    "- `y`: 출력 벡터 (`m × 1`)\n",
    "\n",
    "이제 Loss function `L(y)`에 대해 역전파할 때,  \n",
    "**입력 x에 대한 gradient**는 다음과 같이 transpose를 통해 구해진다: ∂L/∂x = Wᵀ ∂L/∂y\n",
    "\n",
    "\n",
    "즉, **출력 y에 대한 gradient를 Wᵀ에 곱해줘야 input gradient가 나옴**.  \n",
    "이때 W의 transpose가 등장하는 것!\n",
    "\n",
    "- **열벡터 vs 행벡터 변환**  \n",
    "벡터 표현을 바꿀 때 자주 사용 (예: `row vector → column vector`)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 2. Trace (대각합)\n",
    "\n",
    "> `tr(A)` = 정사각행렬 `A`의 대각선 성분들의 합\n",
    "\n",
    "---\n",
    "\n",
    "#### 💡 Trace의 활용 예\n",
    "\n",
    "- **행렬 정보량 요약**  \n",
    "`tr(AᵀA)` = A의 Frobenius norm² (행렬 크기)\n",
    "\n",
    "- **고유값의 합**  \n",
    "`tr(A) = λ₁ + λ₂ + ... + λₙ`\n",
    "\n",
    "- **최적화 문제에서 사용**  \n",
    "예: PCA에서 등장하는 목적함수  \n",
    "`min tr(Wᵀ X Xᵀ W)`\n",
    "\n",
    "- **통계: 총 분산 계산**  \n",
    "다변량 정규분포의 공분산 행렬의 trace는 전체 분산을 나타냄\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 요약 표\n",
    "\n",
    "| 개념 | 정의 | 주요 용도 |\n",
    "|------|------|-----------|\n",
    "| **Transpose `Aᵀ`** | 행과 열을 뒤집음 | 내적 계산, 대칭 행렬, 역전파, 벡터 변환 |\n",
    "| **Trace `tr(A)`** | 정방행렬의 대각합 | 고유값 합, 행렬의 총 에너지, 최적화, 통계 |\n",
    "\n",
    "---\n",
    "\n",
    "> 🔹 **Transpose**는 행/열 변환과 내적 계산의 핵심 도구이며, **딥러닝의 역전파에도 필수**  \n",
    "> 🔹 **Trace**는 행렬 구조를 압축 요약하는 **수학적 합계** 역할을 하며, 고유값 합, 최적화, 통계 분석 등에 쓰임.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
